{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data & Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve data from web so that analysis can be replicated anywhere\n",
    "urlretrieve(\"https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/global-shark-attack/exports/csv?lang=en&timezone=Europe%2FLondon&use_labels=true&delimiter=%3B\", \"global-shark-attack.csv\")\n",
    "\n",
    "# create DataFrame for easy manipulation\n",
    "df = pd.read_csv(\"global-shark-attack.csv\", sep = \";\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disaplying all rows\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "# these columns were not necessary for the analysis\n",
    "df = df.drop(columns=[\"Investigator or Source\", \"pdf\", \"href formula\", \"href\"])\n",
    "\n",
    "df = df.rename(columns={\"Sex \":\"Sex\"}) # removing space for ease\n",
    "\n",
    "#this analysis was only interested in Unprovoked attacks in recent years (attacks pre 1950 often were strange in nature)\n",
    "df = df[df['Type'] == 'Unprovoked']\n",
    "df = df[df['Year'] > 1950]\n",
    "\n",
    "df['Year'] = df['Year'].astype('int')\n",
    "df['Activity'] = df['Activity'].astype('str')\n",
    "df['Time'] = df['Time'].astype('str')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing incorrect values so that we could groupby region and country\n",
    "df['Country'] = df['Country'].str.title()\n",
    "\n",
    "df['Country'] = df['Country']\\\n",
    "    .replace(\"England\", \"United Kingdom\")\\\n",
    "    .replace(\"Egypt / Israel\", \"Egypt\")\\\n",
    "    .replace(\"Okinawa\", \"Japan\")\\\n",
    "    .replace(\"Persian Gulf\", \"Iran\")\\\n",
    "    .replace(\"Red Sea\", \"Jordan\")\\\n",
    "    .replace(\"Reunion\", \"Reunion Island\")\\\n",
    "    .replace(\"United Arab Emirates (Uae)\", \"United Arab Emirates\")\n",
    "\n",
    "df['Area'] = df['Area'].replace([\"Baja California Sur\", \"Baja\", \"Baja California\"], \"California\")\\\n",
    "    .replace(\"New South ales\", \"New South Wales\")\\\n",
    "    .replace([\"New Ireland, Bismarck Archipelago\", \"New Britain, Bismarck Archipelago\",\\\n",
    "        \"New Ireland Province, Bismarck Archipelago\"], \"Bismarck Archipelago\")\\\n",
    "    .replace(\"KwaZulu-Natal between Port Edward and Port St Johns\", \"KwaZulu-Natal\")\\\n",
    "    .replace([\"South Devon\", \"Devon\", \"Cornwall\"], \"South West\")\\\n",
    "    .replace([\"Franklin County, Florida\", \"Florida Straits\"], \"Florida\")\\\n",
    "    .replace([\"Eastern Cape  Province\", \"Eastern Province\"], \"Eastern Cape Province\")\\\n",
    "    .replace(\"Hurghada, Red Sea Governorate\", \"Red Sea\")\\\n",
    "    .replace(\"Sharjah,\", \"Sharjah\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datetime cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # displaying all rows for visibility\n",
    "# pd.set_option('display.max_rows', 10000)\n",
    "# lst = []\n",
    "# for string in df[\"Time\"].drop_duplicates():\n",
    "#     if re.search(\"!?\\d{2}h\\d{2}\", string) == None:\n",
    "#         lst.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst =  ['After noon',\n",
    "#  'Noon',\n",
    "#  'Just before dawn',\n",
    "#  '10j30',\n",
    "#  'A.M.',\n",
    "#  'Just before noon',\n",
    "#  'P.M.',\n",
    "#  'Midnight',\n",
    "#  'Dawn',\n",
    "#  '',\n",
    "#  '2 hours after Opperman',\n",
    "#  '1600',\n",
    "#  'Daybreak',\n",
    "#  '10jh45',\n",
    "#  'Mid-morning',\n",
    "#  '11hoo',\n",
    "#  '9h00',\n",
    "#  'Early  morning',\n",
    "#  'X',\n",
    "#  '1300.0',\n",
    "#  'AM',\n",
    "#  'After Dusk',\n",
    "#  'Mid afternoon',\n",
    "#  'Just before sundown',\n",
    "#  'Midday.',\n",
    "#  'After dark',\n",
    "#  'night',\n",
    "#  '0500',\n",
    "#  'Late morning',\n",
    "#  '30 minutes after 1992.07.08.a',\n",
    "#  '06j00']\n",
    "\n",
    "# for item in lst:\n",
    "#     print(f\".replace('{item}', '____')\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Time\"] = df[\"Time\"].replace(\"Afternoon\", \"15h00\")\\\n",
    "    .replace(\"Morning\", \"09h00\")\\\n",
    "    .replace(\"Lunchtime\", \"13h00\")\\\n",
    "    .replace(\"0830\", \"08h30\")\\\n",
    "    .replace([\"Early Morning\", \"Early morning\"], \"08h00\")\\\n",
    "    .replace(\"Midday\", \"12h00\")\\\n",
    "    .replace([\"Dusk\", \"19h00, Dusk\"], \"19h00\")\\\n",
    "    .replace(\"14h00 - 15h00\", \"14h30\")\\\n",
    "    .replace([\"Late Afternoon\", \"Late afternoon\", \"16h30 or 18h00\"], \"16h30\")\\\n",
    "    .replace(\"Evening\", \"18h30\")\\\n",
    "    .replace(\"11h115\", \"11h15\")\\\n",
    "    .replace([\"Early Afternoon\", \"Early afternoon\"], \"14h00\")\\\n",
    "    .replace(\"Night\", \"19h00\")\\\n",
    "    .replace(\"15h00 or 15h45\", \"15h30\")\\\n",
    "    .replace(\"08h00 / 09h30\", \"08h45\")\\\n",
    "    .replace(\"Before 10h00\", \"09h30\")\\\n",
    "    .replace([\"14h00  -15h00\", \"14h00-15h00\"], \"14h30\")\\\n",
    "    .replace(\"--\", \"\")\\\n",
    "    .replace([\"Mid morning\", \"09h00-10h00\"], \"09h30\")\\\n",
    "    .replace(\"10h00 -- 11h00\", \"10h30\")\\\n",
    "    .replace(\"8:04 pm\", \"20h00\")\\\n",
    "    .replace('Sunset', \"19h00\")\\\n",
    "    .replace('After noon', '15h00')\\\n",
    "    .replace('Noon', '12h00')\\\n",
    "    .replace('Just before dawn', '05h30')\\\n",
    "    .replace('10j30', '10h30')\\\n",
    "    .replace('A.M.', '10h30')\\\n",
    "    .replace('Just before noon', '11h30')\\\n",
    "    .replace('P.M.', '17h00')\\\n",
    "    .replace('Midnight', '00h00')\\\n",
    "    .replace('Dawn', '6h30')\\\n",
    "    .replace('', \"\")\\\n",
    "    .replace('2 hours after Opperman', '')\\\n",
    "    .replace('1600', '16h00')\\\n",
    "    .replace('Daybreak', '06h30')\\\n",
    "    .replace('10jh45', '10h45')\\\n",
    "    .replace('Mid-morning', '10h30')\\\n",
    "    .replace('11hoo', '11h00')\\\n",
    "    .replace('9h00', '09h00')\\\n",
    "    .replace('Early  morning', '07h00')\\\n",
    "    .replace('X', '')\\\n",
    "    .replace('1300.0', '13h00')\\\n",
    "    .replace('AM', '08h00')\\\n",
    "    .replace('After Dusk', '19h00')\\\n",
    "    .replace('Mid afternoon', '15h00')\\\n",
    "    .replace('Just before sundown', '17h30')\\\n",
    "    .replace('Midday.', '12h00')\\\n",
    "    .replace('After dark', '20h00')\\\n",
    "    .replace('night', '21h00')\\\n",
    "    .replace('0500', '05h00')\\\n",
    "    .replace('Late morning', '11h30')\\\n",
    "    .replace('30 minutes after 1992.07.08.a', '')\\\n",
    "    .replace('06j00', '06h00')\n",
    "\n",
    "df['Date'] = df['Date'].replace(\"1018-06-01\", \"2018-06-01\")\\\n",
    "    .replace(\"202-07-10\", \"2020-07-10\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'], format=\"%Y/%m/%d\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_activity(activity):\n",
    "    # if pd.isnull(activity):\n",
    "    #     return \"Unknown\"\n",
    "    # else:\n",
    "    activity = str(activity).lower()\n",
    "    if re.search(\"(body|boogie).*?(boarding|surfing)\", activity):\n",
    "        return \"Body Boarding\"\n",
    "    elif re.search(\"kite.*?(boarding|surfing)\", activity):\n",
    "        return \"Kite Surfing\"\n",
    "    elif re.search(\"wind.*?surfing\", activity):\n",
    "        return \"Wind Surfing\"\n",
    "    elif re.search(\"(paddle|surf).*?ski\", activity):\n",
    "        return \"Surf Skiing\"\n",
    "    elif re.search(\"paddle.*?boarding|sup\", activity):\n",
    "        return \"SUP\"\n",
    "    elif re.search(\"wade|wading\", activity):\n",
    "        return \"Wading\"\n",
    "    elif re.search(\"swim\", activity):\n",
    "        return \"Swimming\"\n",
    "    elif re.search(\"kayak\", activity):\n",
    "        return \"Kayaking\"\n",
    "    elif re.search(\"spear\", activity):\n",
    "        return \"Spearfishing\"\n",
    "    elif re.search(\"snorkel\", activity):\n",
    "        return \"Snorkeling\"\n",
    "    elif re.search(\"diving\", activity):\n",
    "        return \"Diving\"\n",
    "    elif re.search(\"fishing\", activity):\n",
    "        return \"Fishing\"\n",
    "    elif re.search(\"foil\", activity):\n",
    "        return \"Foiling\"\n",
    "    elif re.search(\"float\", activity):\n",
    "        return \"Wading\"\n",
    "    elif re.search(\"\\bsurf|surf[a-z]*\", activity):\n",
    "        return \"Surfing\"\n",
    "    else:\n",
    "        return str(activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Activity\"] = df['Activity'].apply(cleaning_activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_low_counts(df, column):\n",
    "    for value in df[column]:\n",
    "        if df[df[column] == value][column].count() < 5:\n",
    "            df = df.drop(df[df[column] == value].index, axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_low_counts(df, 'Activity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Case Number               object\n",
       "Date              datetime64[ns]\n",
       "Year                       int64\n",
       "Type                      object\n",
       "Country                   object\n",
       "Area                      object\n",
       "Location                  object\n",
       "Activity                  object\n",
       "Name                      object\n",
       "Sex                       object\n",
       "Age                       object\n",
       "Injury                    object\n",
       "Fatal (Y/N)               object\n",
       "Time                      object\n",
       "Species                   object\n",
       "Case Number.1             object\n",
       "Case Number.2             object\n",
       "original order           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
